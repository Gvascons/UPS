# UPS - Universal Problem Solver

A sophisticated multi-modal AI system that implements two complementary approaches to problem-solving: **Solution Generation** (Mode 1) and **Solution Evolution** (Mode 2).

## ğŸ¯ System Overview

UPS combines systematic problem-solving with iterative improvement to tackle complex challenges across domains. The system uses LangGraph workflows, multi-agent coordination, and persistent state management to deliver robust solutions.

### Architecture Modes

- **Mode 1 (Solver)**: âœ… **Implemented** - Generates solutions from scratch using Plan-Execute methodology
- **Mode 2 (Evolver)**: ğŸš§ **Planned** - Evolves and optimizes existing solutions through iterative refinement

## ğŸ—ï¸ Project Structure

```
UPS/
â”œâ”€â”€ UPS/
â”‚   â”œâ”€â”€ solver/          # Mode 1: Solution Generation
â”‚   â”‚   â”œâ”€â”€ engine.py    # Main entry point with CLI and streaming
â”‚   â”‚   â”œâ”€â”€ graph.py     # LangGraph workflow definition
â”‚   â”‚   â”œâ”€â”€ nodes.py     # Planner â†’ Agent â†’ Replanner nodes
â”‚   â”‚   â”œâ”€â”€ schemas.py   # State management and structured outputs
â”‚   â”‚   â”œâ”€â”€ prompts.py   # Specialized prompts for each workflow stage
â”‚   â”‚   â”œâ”€â”€ tools.py     # Python execution + web search tools
â”‚   â”‚   â”œâ”€â”€ utils.py     # Graph visualization utilities
â”‚   â”‚   â””â”€â”€ config.py    # Configuration constants
â”‚   â”‚
â”‚   â”œâ”€â”€ evolver/         # Mode 2: Solution Evolution (Planned)
â”‚   â”‚   â””â”€â”€ ...          # Future implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ context.txt      # Problem input file
â”‚   â”œâ”€â”€ main.py          # System orchestrator
â”‚   â””â”€â”€ meta_controller.py # Mode selection logic
â”‚
â”œâ”€â”€ metadata/            # Intermediate files and step tracking
â”œâ”€â”€ output/              # Final deliverable files
â””â”€â”€ reference/           # Analysis reference (adam system)
```

## ğŸ”§ Mode 1: Solution Generation

### Workflow Architecture

The solver implements a **Plan â†’ Execute â†’ Replan** cycle:

```mermaid
graph LR
    A[START] --> B[Planner]
    B --> C[Agent]
    C --> D[Replanner]
    D --> C
    D --> E[END]
```

### Core Components

**ğŸ§  Planner Node**
- Breaks down complex problems into actionable steps
- Creates structured execution plans with tool awareness
- Handles LLM structured output with fallback parsing

**âš¡ Agent Node** 
- Executes plan steps using ReAct pattern (max 7 iterations)
- Integrates with tools: `execute_python_code` + `web_search`
- Maintains persistent state across execution steps

**ğŸ”„ Replanner Node**
- Evaluates progress after each step execution
- Decides: Continue (new plan) vs Complete (final response)
- Handles completion criteria and error recovery

### Tool Ecosystem

**ğŸ Python Execution**
- Isolated subprocess execution with 60s timeout
- Comprehensive error handling and output capture
- Supports data processing, ML, calculations, file I/O

**ğŸŒ Web Search**
- DuckDuckGo integration for research and information gathering
- Result filtering and content summarization
- Documentation and example discovery

### File Management Strategy

**ğŸ“ Directory Usage**
- `metadata/`: Intermediate artifacts, research findings, step-by-step tracking
- `output/`: Final deliverable files when explicitly requested by problem

**ğŸ’¾ Persistent State**
- Cross-step file sharing for complex workflows
- Automatic directory creation and management
- Descriptive file naming for step continuity

## ğŸš€ Usage

### Basic Execution
```bash
# Run with default context.txt
python -m UPS.solver.engine

# Custom input file
python -m UPS.solver.engine --input_file my_problem.txt

# Enable Langfuse tracing
python -m UPS.solver.engine --enable_tracing
```

### Example Problem (current context.txt)
```
Create a machine learning model to predict house prices using the Boston housing dataset. 
Include data preprocessing, model training, evaluation, and save the results to a CSV file.
```

### Expected Output Structure
```
metadata/
â”œâ”€â”€ step1_research.txt      # Dataset and approach research
â”œâ”€â”€ step2_data.csv          # Preprocessed dataset
â”œâ”€â”€ step3_model.pkl         # Trained model artifacts
â””â”€â”€ step4_evaluation.txt    # Model performance metrics

output/
â”œâ”€â”€ house_price_predictions.csv  # Final predictions
â””â”€â”€ model_report.txt              # Summary report
```

## ğŸ”¬ Technical Features

### LLM Integration
- **Multi-Provider Support**: OpenAI, Anthropic, Google Gemini
- **Structured Outputs**: Pydantic models with manual parsing fallbacks
- **Error Recovery**: Graceful degradation when LLM calls fail

### Execution Management
- **Async Streaming**: Real-time progress updates during execution
- **State Persistence**: Operator-based state merging with `past_steps` accumulation
- **Timeout Handling**: 60-second limits on code execution with proper cleanup

### Observability
- **Langfuse Tracing**: Optional execution tracking and performance monitoring
- **Graph Visualization**: Automatic workflow diagram generation
- **Comprehensive Logging**: Debug, info, warning, and error level tracking

### Quality Assurance
- **Comprehensive Testing**: 24/24 test coverage for tools and core functionality
- **Error Handling**: Graceful failures at each workflow node
- **Validation**: Input validation and state consistency checks

## ğŸ“‹ Dependencies

### Core Requirements
```
langgraph>=0.2.0          # Workflow orchestration
langchain>=0.3.0          # LLM framework
pydantic>=2.0.0           # Structured data validation
duckduckgo-search         # Web search functionality
python-dotenv             # Environment management
langfuse                  # Optional: Execution tracing
```

### LLM Providers (Choose One)
```
langchain-openai          # OpenAI GPT models
langchain-anthropic       # Anthropic Claude models  
langchain-google-genai    # Google Gemini models
```

## ğŸ¯ Mode 2: Evolution (Planned)

The evolution system will implement:

**ğŸ§¬ Solution Refinement**
- Iterative improvement of Mode 1 solutions
- Performance-based optimization cycles
- Multi-criteria evaluation frameworks

**ğŸ”„ Adaptive Learning**
- Solution pattern recognition and reuse
- Dynamic strategy adjustment based on problem types
- Cross-domain knowledge transfer

**ğŸ“Š Evaluation Systems**
- Automated solution quality assessment
- Comparative analysis across solution variants
- Success metrics tracking and optimization

## ğŸ¤ Contributing

This system represents a foundation for systematic AI problem-solving. The current Mode 1 implementation provides robust solution generation, while Mode 2 will add evolutionary capabilities for solution optimization.

### Development Priorities
1. âœ… Mode 1 core functionality and testing
2. ğŸš§ Mode 2 evolution framework design
3. ğŸ”® Multi-agent coordination enhancements
4. ğŸ”® Advanced evaluation and optimization systems

## ğŸ“Š Performance Characteristics

- **Execution Speed**: Typical problems resolve in 2-10 minutes
- **Success Rate**: High completion rate with graceful error handling
- **Resource Usage**: Moderate computational requirements with configurable timeouts
- **Scalability**: Designed for complex, multi-step problems requiring tool usage

## ğŸ” Configuration

### Environment Variables
```bash
# Required for LLM providers
OPENAI_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here  
GOOGLE_API_KEY=your_key_here

# Optional: Langfuse tracing
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_PUBLIC_KEY=your_public_key
```

### System Settings
- **Metadata Directory**: `metadata/` (configurable via `config.py`)
- **Output Directory**: `output/` (configurable via `config.py`)
- **Execution Timeout**: 60 seconds per tool call
- **ReAct Iterations**: Maximum 7 per agent execution

---

*UPS represents a systematic approach to AI-powered problem solving, combining the reliability of structured workflows with the flexibility of multi-agent systems.*
